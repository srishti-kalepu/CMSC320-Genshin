{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e0425878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --ignore-installed --upgrade tensorflow \n",
    "#%pip install opencv-python\n",
    "#%pip install --upgrade albumentations --user\n",
    "#%pip install pandas\n",
    "#%pip install numpy\n",
    "#%pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "810fbd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import vgg19\n",
    "import albumentations as A # used for image augmentation\n",
    "from PIL import Image #used for importing images\n",
    "import re\n",
    "import os,glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , MaxPooling2D\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "07cfa87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Model</th>\n",
       "      <th>Region</th>\n",
       "      <th>Vision</th>\n",
       "      <th>Weapon</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Year Released</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albedo</td>\n",
       "      <td>https://i.postimg.cc/vHqgw9cj/unnamed.jpg</td>\n",
       "      <td>Mondstadt</td>\n",
       "      <td>Geo</td>\n",
       "      <td>Sword</td>\n",
       "      <td>$11,816,107</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ayaka</td>\n",
       "      <td>https://i.postimg.cc/mZP9x58Q/ayaka.jpg</td>\n",
       "      <td>Inazuma</td>\n",
       "      <td>Cryo</td>\n",
       "      <td>Sword</td>\n",
       "      <td>$16,451,006</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ayato</td>\n",
       "      <td>https://i.postimg.cc/3JpDNDMN/ayato.jpg</td>\n",
       "      <td>Inazuma</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>Sword</td>\n",
       "      <td>$14,481,796</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Childe (Tartaglia)</td>\n",
       "      <td>https://i.postimg.cc/RZBJHV9R/childe.jpg</td>\n",
       "      <td>Liyue</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>Bow</td>\n",
       "      <td>$13,443,619</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cyno</td>\n",
       "      <td>https://i.postimg.cc/bNHN40cx/cyno.jpg</td>\n",
       "      <td>Sumeru</td>\n",
       "      <td>Electro</td>\n",
       "      <td>Polearm</td>\n",
       "      <td>$13,797,833</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name                                      Model     Region  \\\n",
       "0              Albedo  https://i.postimg.cc/vHqgw9cj/unnamed.jpg  Mondstadt   \n",
       "1               Ayaka    https://i.postimg.cc/mZP9x58Q/ayaka.jpg    Inazuma   \n",
       "2               Ayato    https://i.postimg.cc/3JpDNDMN/ayato.jpg    Inazuma   \n",
       "3  Childe (Tartaglia)   https://i.postimg.cc/RZBJHV9R/childe.jpg      Liyue   \n",
       "4                Cyno     https://i.postimg.cc/bNHN40cx/cyno.jpg     Sumeru   \n",
       "\n",
       "    Vision   Weapon      Revenue  Year Released  \n",
       "0      Geo    Sword  $11,816,107           2021  \n",
       "1     Cryo    Sword  $16,451,006           2021  \n",
       "2    Hydro    Sword  $14,481,796           2022  \n",
       "3    Hydro      Bow  $13,443,619           2020  \n",
       "4  Electro  Polearm  $13,797,833           2022  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./Genshin_Dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c3b2d1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the filepath to the image, we can visualize the image\n",
    "def visualize(image):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "27b6e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformations\n",
    "vertical_transform = A.Compose([A.VerticalFlip(p=1)])\n",
    "horizontal_transform = A.Compose([A.HorizontalFlip(p=1)])\n",
    "#clahe_transform = A.Compose([A.CLAHE(p=1)]) # enhances the picture's contrast and brightness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "14fd7449",
   "metadata": {},
   "outputs": [],
   "source": [
    "revenues = data['Revenue']\n",
    "revenues = revenues.map(lambda x: int(re.sub(\",\", \"\", x[1:]))) # removes $ and commas from the revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e93f7328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterates over the character images in the folder \n",
    "# returns a tuple where the 3rd element is a list of the character names\n",
    "images_arr = []\n",
    "revenue_arr = []\n",
    "counter = 0\n",
    "for e_image in os.walk('./Genshin Characters/'):\n",
    "    #print(e_image)\n",
    "\n",
    "    # iterates over the list of the character names\n",
    "    for img_name in e_image[2]:\n",
    "        #curr = []\n",
    "        file_path = './Genshin Characters/{}'.format(img_name)\n",
    "        image = cv2.imread(file_path, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (200, 200))#, interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        ###image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = np.array(image)\n",
    "        image = image.astype('float32')\n",
    "        image /= 255\n",
    "        \n",
    "        \n",
    "        \n",
    "        #curr.append(image)\n",
    "        # transform function takes in the image as the parameter\n",
    "        # the output is a dictionary with 'image' as the key and the transformed image as the value\n",
    "        # so, we extract the value by giving it the key\n",
    "        ##vertical_image = vertical_transform(image=image)['image'] \n",
    "        ##horizontal_image = horizontal_transform(image=image)['image']\n",
    "        ##both_image = horizontal_transform(image=vertical_image)['image']\n",
    "        #clahe_image = clahe_transform(image=image)['image']\n",
    "        #visualize(image) \n",
    "        #visualize(vertical_image)\n",
    "        #visualize(horizontal_image)\n",
    "        #visualize(both_image)\n",
    "        #visualize(clahe_image)\n",
    "        #curr.append(vertical_image)\n",
    "        #curr.append(horizontal_image)\n",
    "        #curr.append(both_image)\n",
    "        images_arr.append(image)\n",
    "        ##images_arr.append(vertical_image)\n",
    "        ##images_arr.append(horizontal_image)\n",
    "        ##images_arr.append(both_image)\n",
    "        ##revenue_arr.append(revenues[counter])\n",
    "        ##revenue_arr.append(revenues[counter])\n",
    "        ##revenue_arr.append(revenues[counter])\n",
    "        revenue_arr.append(revenues[counter])\n",
    "        counter += 1\n",
    "\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9e19a3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_23 (InputLayer)       [(None, 200, 200, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 200, 200, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 200, 200, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 100, 100, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 100, 100, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 100, 100, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 50, 50, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 50, 50, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 50, 50, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 50, 50, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 50, 50, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 25, 25, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 25, 25, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 12, 12, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d_14  (None, 512)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = vgg19.VGG19(include_top=False,weights = 'imagenet', input_shape=(200, 200,3),pooling='avg')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a07b471a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "print(len(revenue_arr))\n",
    "print(len(images_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8dd9679d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x00000220D0CBA050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 23s 23s/step - loss: 151867168.0000 - accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 19s 19s/step - loss: 14803025.0000 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22124de1180>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(images_arr)\n",
    "#images_arr1 = np.array(images_arr)\n",
    "#revenue_arr1 = np.array(revenue_arr)\n",
    "#images_arr2=np.asarray(images_arr).astype(object)\n",
    "#revenue_arr2 = np.asarray(revenue_arr).astype(object)\n",
    "\n",
    "img_train, img_test, rev_train, rev_test = train_test_split(images_arr, revenue_arr, test_size=0.2, shuffle = True, random_state = 20)\n",
    "#model.compile(loss=\"mse\", optimizer=keras.optimizers.Adadelta())\n",
    "#print(images_arr)\n",
    "#print(img_train)\n",
    "#print(img_test)\n",
    "#print(rev_train.shape)\n",
    "#print(rev_test.shape)\n",
    "#img_train_tf = tf.convert_to_tensor(img_train, dtype = object)\n",
    "#data_set = tf.data.Dataset.from_tensor_slices(img_train, rev_train)\n",
    "\n",
    "#model=tf.keras.Sequential(\n",
    "       # [\n",
    "        #    tf.keras.layers.InputLayer(input_shape=(200,200, 3)),\n",
    "        #    tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "         #   tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "         #   tf.keras.layers.Flatten()\n",
    "      #  ])\n",
    "            #tf.keras.layers.Dense(34000000)\n",
    "        \n",
    "model.compile(optimizer='adam', loss='mae', metrics=['accuracy'])\n",
    "model.fit(np.array(img_train, np.float32), np.array(list(map(int, rev_train)), np.float32), epochs=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6993d91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "1af2ab16b1a3a40328f305e50c95b28c2b6b44b66386a6d1e962276a7fd39f3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
